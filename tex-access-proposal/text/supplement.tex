\section{Application Form Questions}

\subsection{Project Title}

\subsection{Public overview}

\begin{displayquote} \itshape
Your overview should touch on your project's goals, how you plan to use ACCESS resources, and any software packages you need.
Covering these topics helps us ensure you get connected with appropriate resources for your work.
\end{displayquote}

\subsection{Keywords}

agent-based modeling, digital evolution, genetic algorithms, phylogenetics, evolutionary biology

\subsection{Fields of Science}

\begin{enumerate}
    \item Systems and Population Biology
    \item Other Computer and Information Sciences
\end{enumerate}

\subsection{How many CS-2 hours are requested? Provide comments.}

40 hours

We anticipate that half an hour of computetime for each replicate will be sufficient to observe extremely deep evolutionary processes (i.e., on the order of a million generations).
So, 10 hours for the validation experiments

For the scaling experiments, 10 minutes of runtime times ten replicates times three scale treatments is 5 hours.

TODO how many hours for the other experiments?

We have included an extra 10 hours for any unforseen circumstances.

\subsection{Describe your research team.}

\begin{displayquote} \itshape
Please, describe your research team and make sure to include expected roles in the proposed research, current affiliation, academic status, and relevant experience.
Links to professional pages or attached documents that describe relevant experience and qualifications are welcomed.
\end{displayquote}

The lead researcher on this project is Dr. Matthew Andres Moreno.
Dr. Moreno is a postdoctoral researcher at University of Michigan with affiliations with the Ecology and Evolutionary Biology Department, the Center for the Study of Complex Systems, and the Michigan Institute for Data Science.
His work is supported through the Schmidt AI in Science postdoctoral fellowship.

TODO talk about development of hstrat, DISHTINY, and Conduit.
More information about Dr. Moreno's research can be found at \url{https://mmore500.com/research/}.

Dr. Emily Dolson and Dr. Luis Zaman are close collaborators, taking on an advisory role in this project.

Dr. Zaman is an assistant professor at University of Michigan with affiliations to Ecology and Evolutionary Biology and the Center for the Study of Complex Systems.
TODOagent-based modeling, although he has since also developed a strong.
Dr. Zaman serves as Dr. Moreno's postdoctoral advisor.

Dr. Emily Dolson is an assistant processor at Michigan State University, primarily affiliated to the Computer Science and Engineering department.
She is also affiliated with the Ecology, Evolution, and Behavior program.
TODO talk about expertise with phylogenetic methods and involvement devleloping hstrat methods/software.

Undergraduate researchers Connor Yang and Anika Ranjan are involved in the project through the Undergraduate Research Opportunities Program at University of Michigan.
Connor's primary role is in software development, including contributing Cerebras Software Language code to be used in the project.
Anika's role has been in data analysis for experiments testing the algorithmic properties of hereditary stratigraphy approaches.
Both undergraduate students work under the supervision of Dr. Moreno.

\subsection{Which Neocortex Application Track?}

Track 3: General purpose SDK

\begin{displayquote} \itshape
This track is for researchers who intend to leverage the Cerebras SDK to develop custom compute kernels.
The SDK is for researchers who want to explore the fundamental mapping of algorithms to a gigantic rectangular mesh of independent processors with a unique memory architecture.
Ongoing research work with the SDK includes a collaboration with an energy company to implement a finite difference method for seismic wave equations and the implementation of Graph 500 benchmark algorithms.

Some potential research avenues of interest are the implementation of HPC benchmark algorithms, such as HPL (high-performance LINPACK) and HPCG (high-performance conjugate gradient), optimal mappings of sparse tensor operations, linear solvers, particle methods, or graph algorithms, for instance.

The SDK can also be used to explore the implementation of custom machine learning kernels on the CS-2.
Note however, that the SDK is not currently interoperable with the CS-2's PyTorch and TensorFlow frontends, and can only be used to write standalone code.
Also, note that existing code written in other languages cannot be used as-is.

To better understand what leveraging the SDK entails, it can be helpful to envision what CUDA development would look like for a specific GPU architecture.
\end{displayquote}

\subsection{Did you address all the questions associated with the track(s) in an attached application PDF document?}

\begin{displayquote} \itshape
    \begin{itemize}
    \item \url{https://portal.neocortex.psc.edu/docs/index.html}
    \item \url{https://www.cmu.edu/psc/aibd/neocortex/2023-11-neocortex-project-tracks.html}
    \end{itemize}
\end{displayquote}

\begin{displayquote} \itshape
    \begin{enumerate}
    \item Using the SDK requires programming in CSL, a C-like language designed specifically for the problem of massively parallel programming on the CS-2.
    What is your experience with HPC programming paradigms and languages, such as MPI, OpenMP, CUDA, OpenCL, etc.?
    \item What are the underlying computational algorithms you're interested in exploring?
    What existing software packages or libraries use these algorithms?
    \item How is this problem bottlenecked on current hardware?
    Is the problem more bottlenecked by memory bandwidth, or communication costs associated with scaling up across distributed compute nodes?
    \item What range of problem sizes are you interested in addressing?
    For example, how much memory does your problem use?
    How does memory usage or program run-time scale with problem size?
    \item What portion of your algorithm do you plan to port to the CS-2?
    Why are you interested in exploring this part of your algorithm?
    \item The CS-2 offers native half and single precision data types.
    What precision does your algorithm or use case need?
    \item The CS-2 is a network-attached accelerator. At a high level, the CSL programming model is similar to that of CUDA, in which data is moved between host CPU nodes and the device (CS-2) on which computational kernels are launched.
    How often will data need to be moved between the wafer and the worker nodes?
    \item Describe your general plan to map your problem onto 850,000 cores. In answering this question, it might be helpful to recall some details of the CS-2 architecture.
    The 850,000 cores are laid out in a mesh, with each core connected on fabric to its four nearest neighbors on the East, South, North, and West.
    Memory is distributed among the cores, with each core having 48 KB of local memory.
    64-bit local memory reads and writes take roughly a cycle, as does sending and receiving 32-bit messages between the four neighboring cores.
    \end{enumerate}
\end{displayquote}
